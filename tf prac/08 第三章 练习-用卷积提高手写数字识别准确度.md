## Exercise 3
In the videos you looked at how you would improve Fashion MNIST using Convolutions. For your exercise see if you can improve MNIST to 99.8% accuracy or more using only a single convolutional layer and a single MaxPooling 2D. You should stop training once the accuracy goes above this amount. It should happen in less than 20 epochs, so it's ok to hard code the number of epochs for training, but your training must end once it hits the above metric. If it doesn't, then you'll need to redesign your layers.

I've started the code for you -- you need to finish it!

When 99.8% accuracy has been hit, you should print out the string "Reached 99.8% accuracy so cancelling training!"

## 练习3
在视频中，你看了如何使用卷积来提高Fashion MNIST的识别率。通过这个练习，看看可否只使用单个卷积层和单个MaxPooling 2D将MNIST（手写数字）识别率提高到99.8%或更高的准确率。一旦准确率超过这个数值，应该停止训练。Epochs不应超过20个。如果epochs达到20但精度未达到要求，那么就需要重新设计层结构。

程序的框架已经有了--请完成它!

当达到99.8%的准确率时，你应该打印出 "达到99.8%准确率，所以取消训练！"的字符串。


```python
%config IPCompleter.greedy = True
```


```python
import tensorflow as tf

# YOUR CODE STARTS HERE
class MyCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self,epoch,logs = {}):
        if(logs.get('acc')>0.998):
            print("\nAccuracy reached!")
            self.model.stop_training = True
            
callbacks = MyCallback()
# YOUR CODE ENDS HERE

mnist = tf.keras.datasets.mnist
(training_images, training_labels), (test_images, test_labels) = mnist.load_data()

# YOUR CODE STARTS HERE
training_images = training_images.reshape((-1,28,28,1))/255.
test_images = test_images.reshape((-1,28,28,1))/255.
# YOUR CODE ENDS HERE

model = tf.keras.models.Sequential([
    # YOUR CODE STARTS HERE
    tf.keras.layers.Conv2D(16,(3,3),activation = 'relu',input_shape=(28,28,1)),
    tf.keras.layers.MaxPool2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128,activation = 'relu'),
    tf.keras.layers.Dense(10,activation = 'softmax')
    # YOUR CODE ENDS HERE
])

# YOUR CODE STARTS HERE
model.compile(optimizer = "adam", loss = "sparse_categorical_crossentropy", metrics = ['acc'])
model.fit(training_images,training_labels, epochs = 20, callbacks = [callbacks])

print(model.evaluate(test_images,test_labels))
# YOUR CODE ENDS HERE


```

    Epoch 1/20
    1875/1875 [==============================] - 22s 12ms/step - loss: 0.1689 - acc: 0.9501
    Epoch 2/20
    1875/1875 [==============================] - 22s 12ms/step - loss: 0.0570 - acc: 0.9828
    Epoch 3/20
    1875/1875 [==============================] - 22s 12ms/step - loss: 0.0375 - acc: 0.9886
    Epoch 4/20
    1875/1875 [==============================] - 22s 12ms/step - loss: 0.0246 - acc: 0.9920
    Epoch 5/20
    1875/1875 [==============================] - 21s 11ms/step - loss: 0.0168 - acc: 0.9947
    Epoch 6/20
    1875/1875 [==============================] - 22s 12ms/step - loss: 0.0127 - acc: 0.9959
    Epoch 7/20
    1875/1875 [==============================] - 21s 11ms/step - loss: 0.0089 - acc: 0.9970
    Epoch 8/20
    1875/1875 [==============================] - 21s 11ms/step - loss: 0.0068 - acc: 0.9979
    Epoch 9/20
    1875/1875 [==============================] - 22s 12ms/step - loss: 0.0066 - acc: 0.9979
    Epoch 10/20
    1874/1875 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9984
    Accuracy reached!
    1875/1875 [==============================] - 22s 12ms/step - loss: 0.0052 - acc: 0.9984
    313/313 [==============================] - 2s 5ms/step - loss: 0.0556 - acc: 0.9867
    [0.05564500018954277, 0.9866999983787537]

